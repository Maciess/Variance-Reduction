---
title: "Project 2 Monte Carlo"
author: "Maciej Szczutko"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F)
library(MASS)
```

```{r params}

r <- 0.05
sigma <- 0.25
mu_star <- r - sigma^2
s_0 <- 100
K <- 100

source("helpers.R")

```

# Problem description

We are interested in estimating the following (called an option, with discounted payoff at time 1) with price given by the formula

$$
I=e^{-r} E\left(A_n-K\right)_{+},
$$
where
$$
A_n=\frac{1}{n} \sum_{i=1}^n S(i / n), 
$$
and 
$$
S(t)=S(0) \exp \left(\mu^* t+\sigma B(t)\right), \quad 0 \leq t \leq T
$$
where $B(t)(0 \leq t \leq T)$ is Brownian motion.

TODO: extend interpretation by my own comments.

## European and Asian option

In the case n = 1, this is called a European call option; otherwise, it is called an Asian call option.


## Used methods

  1. Crude Monte Carlo estimator
  2. Stratified estimator
  
  
## Monte Carlo description

TO DO Add brownian motion description. 

First we need to generate Brownian Motion $n$ points, equally spaced sample on $[0,1]$. We will use the fact that $\mathbf{B}=(B(1 / n), B(2 / n), \ldots, B(1))$ is a multivariate normal random variable $\mathcal{N}(\mathbf{0}, \boldsymbol{\Sigma})$ with the covariance matrix

$$
\boldsymbol{\Sigma}(i, j)=\frac{1}{n} \min (i, j).
$$




```{r monte-carlo}

n <- 1


numOfReplicate <- 1000
monteCarloReplicates <- replicate(numOfReplicate, {
gmbSample <- GetGeometricBrownianSample(s_0, r, sigma, n);
A <- mean(gmbSample);
I <- exp(-r) * max(A-K, 0)},
simplify = "vector")
monteCarloEstimator <- mean(monteCarloReplicates)


```


```{r simulation-for-larger-n}
monteCarloSimulation <- function(n, numOfReplicate, s_0, r, sigma, K)
{
  monteCarloReplicates <- replicate(numOfReplicate, {
    gmbSample <- GetGeometricBrownianSample(s_0, r, sigma, n)
    
    A <- mean(gmbSample)
    
    I <- exp(-r) * max(A - K, 0)
  },
  simplify = "vector")
  monteCarloReplicates
}

```

```{r power-of-two}

indexVector <- 2^(0:6)

R <- 1000
mcResults <- as.data.frame(sapply(indexVector, function(i) {monteCarloSimulation(n=i, numOfReplicate = R, s_0, r, sigma, K)}))
names(mcResults) <- indexVector





```

```{r}
library(kableExtra)
mcEstimators <- colMeans(mcResults)
kbl(as.data.frame(t(mcEstimators)), booktabs = T, caption = paste0("MC estimators values for R=", R), digits = 3) %>%
  kable_classic()
```




```{r plot-for-different-n, fig.dim=c(7, 3)}
library(ggplot2)
library(tidyr)


df_long <- pivot_longer(mcResults, cols = everything(), names_to = "Variable", values_to = "Value")
df_long$Variable <- factor(df_long$Variable, levels = names(mcResults))

# Create the boxplot
ggplot(df_long, aes(x = Variable, y = Value)) +
  geom_boxplot(fill = "skyblue", color = "black") +
  labs(title = "Boxplot of Each Column", x = "Columns", y = "Values") +
  theme_minimal()
```


```{r plots-for-MC}
data <- data.frame(
  Value = c(monteCarloReplicates, monteCarloReplicates),
  Group = rep(c("Crude Monte Carlo estimator", "Place holder"), each = 100)
)

ggplot(data, aes(x = Group, y = Value, fill = Group)) +
  geom_boxplot() +
  labs(title = paste("CMCE vs ... for European Option with R =", numOfReplicate),
       x = "Groups",
       y = "Values") +
  theme_minimal() +
  scale_fill_manual(values = c("skyblue", "orange"))


```

## Theoretical calculation for European option using Black-Scholes formula

We can compare the simulation results for European option with theoretical calculation. The formula is

$$
E(S(1)-K)_{+}=S(0) \Phi\left(d_1\right)-K e^{-r} \Phi\left(d_2\right),
$$

where

$$
d_1=\frac{1}{\sigma}\left[\log \left(\frac{S(0)}{K}\right)+r+\frac{\sigma^2}{2}\right],
$$
and

$$
d_2=d_1-\sigma .
$$


```{r black-scholes}
d1 <- (1 / sigma) * (log(s_0 / K) + r + (sigma ^ 2 / 2))
d2 <- d1 - sigma
blackScholes <- (s_0 * pnorm(d1)) - (K * exp(-r) * pnorm(d2))
blackScholes <- exp(-r) * blackScholes
```
Using our setup parameters we obtain value $`r blackScholes`$. It is alaign with the MC simulation result. Even using $R=`r R`$ replication we have quite bias simulation. 

